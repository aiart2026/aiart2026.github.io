<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>AIART2026</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom fonts for this template -->
  <!-- <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
  <link
    href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800'
    rel='stylesheet' type='text/css'>
  <link
    href='https://fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic,900,900italic'
    rel='stylesheet' type='text/css'>

  <!-- Plugin CSS -->
  <link href="vendor/magnific-popup/magnific-popup.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="css/creative.min.css" rel="stylesheet">
  <link rel="icon" type="images/png" href="images/logo1.png">

</head>

<body id="page-top">

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
    <div class="container"style="margin-left: 150px;">
      <a class="navbar-brand js-scroll-trigger" href="#page-top"><img src="images/logo.png" style="height: 50px;" /></a>
      <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse"
        data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false"
        aria-label="Toggle navigation">

        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse justify-content-center" id="navbarResponsive">
        <ul class="navbar-nav">
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#cfp">Call for Papers</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#dates">Dates</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#keynotes">Keynotes</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#program">Conference Program</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#ps">Technical Program Committee</a>
             </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#ppl">Organizers</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#MIR">Partners</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#sponsorship">Sponsorship</a>
              </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#Gallery">Gallery</a>
              </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#Book">Book</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#history">History</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <header class="masthead text-center text-white d-flex">
    <div class="container my-auto">
      <div class="row">
        <div class="col-lg-10 mx-auto">
          <!-- <h2 class="text-uppercase"> -->
          <h2 style="font-size: 36px">
            <strong>The 8<sup>th</sup> IEEE Workshop on <br />
             Artificial Intelligence for
                Art Creation</strong>
          </h2>
          <hr>
        </div>
        <div class="col-lg-8 mx-auto">
          <p class="text-faded mb-5" style="font-size: 24px; font-weight: bold;">Bangkok, Thailand<br />July 5 - July 9, 2026<br />
            Jointly with <a href="https://2026.ieeeicme.org/" target="_blank" style="color: white"><u>ICME
                2026</u></a>
            <br>
          </p>
        </div>
      </div>
    </div>
  </header>

  <section class="bg-primary" id="cfp">
    <div class="container">
      <div class="row">
        <div class="col-lg-10 mx-auto text-center">
          <h2 class="section-heading text-white">Call for Papers</h2>
          <hr class="light my-4">
          <p class="text-faded mb-4" style="text-align: justify; color: white; font-size: 18px">
            Recent advances brought by Multimodal Large Language Model (MLLM), Multimodal Agents, and Embodied Intelligence have been powerful driving forces for art generation and understanding, drawing more and more attention from both academia and industry. Across creative fields, AI has already sparked new genres and experimentations in painting, music, film, storytelling, fashion and design. Researchers explore the human and AI co-creativity as well as the ethical implications of AI arts. AI has been applied to art historical research, cultural heritage revitalization, and media studies. The aesthetic value of AI generated content and AI’s impact on art appreciation have also been a contended subject in recent scholarship. AI has not only exhibited creative potential, but also stimulated research from diverse perspectives of neuroscience, cognitive science, psychology, literature, art history, media and communication studies. Despite all these promising features of AI for Art, we still have to face the many challenges such as the biases in AI models, lack of transparency and interpretability in algorithms, and copyright issues of training data and AI Art works.
          </p>

          <p class="text-faded mb-4" style="text-align: justify; color: white; font-size: 18px">
            This is the 8<sup>th</sup> AIART workshop to be held in conjunction with ICME 2026 in Bangkok, Thailand, and it aims to bring forward cutting-edge technologies and most recent advances in the area of AI art as well as perspectives from related disciplines.
          </p>

          <p class="text-faded mb-4" style="text-align: justify; color: white; font-size: 18px">
            The theme topic of AIART 2026 will be <strong>Multimodal Agents for AI Art</strong>. We plan to invite 5 keynote speakers to present their insightful perspectives on AI art.
          </p>
          <p class="text-faded mb-4" style="text-align: justify; color: white; font-size: 18px">
            We sincerely invite high-quality papers presenting or addressing issues related to AI art, including but not limited to the following topics:
          </p>
        <div style="color:white; text-align:left; font-size:18px; line-height:1.8;">

  <div style="font-weight:bold; margin-top:24px; margin-bottom:8px;">
    Track 1: Theories for AI Art
  </div>
  <ul>
    <li>Neuroscience</li>
    <li>Cognitive science and Psychology</li>
    <li>Aesthetics</li>
    <li>Creativity</li>
    <li>Arts (Fine Arts, Arts and Crafts, Performing Arts, Interdisciplinary Arts, Literature and Art)</li>
  </ul>

  <div style="font-weight:bold; margin-top:24px; margin-bottom:8px;">
    Track 2: AI for Art Generation
  </div>
  <ul>
    <li>AI for painting and calligraphy</li>
    <li>AI for video and movie</li>
    <li>AI for music and audio</li>
    <li>AI for literature</li>
    <li>AI for design</li>
    <li>AI for videogame</li>
    <li>Adaptive expression</li>
  </ul>

  <div style="font-weight:bold; margin-top:24px; margin-bottom:8px;">
    Track 3: AI for Art Understanding
  </div>
  <ul>
    <li>Affective computing</li>
    <li>Aesthetic evaluation</li>
    <li>Multimodal agents</li>
    <li>Embodied intelligence</li>
    <li>World foundation models</li>
  </ul>

  <div style="font-weight:bold; margin-top:24px; margin-bottom:8px;">
    Track 4: AI Art in Extended Reality (XR)
  </div>
  <ul>
    <li>AI-driven procedural generation for VR/AR worlds</li>
    <li>Virtual humans and digital performers</li>
    <li>AI choreography for volumetric video and motion capture</li>
    <li>Physics-aware and interactable generative assets</li>
  </ul>

  <div style="font-weight:bold; margin-top:24px; margin-bottom:8px;">
    Track 5: Human–AI Co-Creation &amp; Interaction
  </div>
  <ul>
    <li>Interactive AI tools for artists</li>
    <li>Real-time co-creation systems</li>
    <li>XR/VR/AR environments for human–AI creative expression</li>
    <li>Human–AI agency and authorship models</li>
    <li>Perception and UX research in creative tool design</li>
  </ul>

  <div style="font-weight:bold; margin-top:24px; margin-bottom:8px;">
    Track 6: AI for Humanity and the Humanities
  </div>
  <ul>
    <li>AI for cultural heritage</li>
    <li>AI for media studies</li>
    <li>AI for social justice</li>
    <li>AI for accessibility</li>
    <li>AI for empathy</li>
    <li>AI for textual analysis</li>
    <li>AI ethics and safety</li>
    <li>Authentication and IPR issues of AI artworks</li>
    <li>Deepfake detection for creative industries</li>
  </ul>

</div>
          <br>
          <p class="text-faded mb-4; " style="text-align: left; color: white; font-size: 18px">
The authors of selected high-quality papers will be invited to submit an extended version to the Machine Intelligence Research (MIR) journal published by Springer, and the Transactions on Artificial Intelligence (TAI) journal published by Scilight.
          </p>
          <p class="text-faded mb-4; " style="text-align: left; color: white; font-size: 18px">
            Additionally, Best Paper Award will be given.
          </p>

          <p class="text-faded mb-4; " style="text-align: left; color: white; font-size: 18px">
            AIART 2026 will continue to organize the 2nd AIART Gallery for artists to showcase their creative AI artworks in the form of in-person gallery. The AIART Gallery will provide a great opportunity for people to experience interactive artworks and communicate creative ideas. 
          </p>
          <br>
          <p class="text-faded mb-4; " style="text-align: left; color: white; font-size: 24px">
            <strong>Paper Submission</strong>
          </p>
          <p class="text-faded mb-4; " style="text-align: left; color: white; font-size: 18px">
            Authors should prepare their manuscript according to the Guide for Authors of ICME available at Author
            Information and Submission Instructions: <a href="https://2026.ieeeicme.org/author-information-and-submission-instructions/"
              target="_blank">https://2026.ieeeicme.org/author-information-and-submission-instructions/</a>
          </p>
          <p class="text-faded mb-4; " style="text-align: left; color: white; font-size: 18px">
            Submission address: <a href="https://cmt3.research.microsoft.com/ICMEW2026"
              target="_blank">https://cmt3.research.microsoft.com/ICMEW2026</a>
          </p>

          <!-- <p class="text-faded mb-4; " style="text-align: left; color: white; font-size: 18px" >
              Submission address: <a href="http://2023.ieeeicme.org/author-info.html"  target="_blank" >http://2023.ieeeicme.org/author-info.html</a>
            </p> -->

          <br>
          <a class="btn btn-light btn-xl js-scroll-trigger" href="https://cmt3.research.microsoft.com/ICMEW2026"
            target="_blank">Submit link</a>
        </div>
      </div>
    </div>
  </section>


  <section id="dates">
    <div class="container">
      <div class="row">
        <div class="col-lg-6 mx-auto text-center">
          <h2 class="section-heading">Important Dates</h2>
          <hr class="dark my-4">
          <table width="100%" cellpadding="10" align="center">
            <tr>
              <td>
                <div class="text-muted" style="text-align: left; font-weight: bold;">Submissions due</div>
              </td>
              <td>
                <div class="text-muted" style="text-align: left;">March 25, 2026</div>
              </td>
            </tr>
            <tr>
              <td>
                <div class="text-muted" style="text-align: left; font-weight: bold;">Workshop date</div>
              </td>
              <td>
                <div class="text-muted" style="text-align: left;">TBD</div>
              </td>
            </tr>


          </table>
          <!-- <a class="btn btn-light btn-xl js-scroll-trigger" href="#services">Get Started!</a> -->
        </div>
      </div>
    </div>
  </section>






  <!-- first -->
  <section  class="bg-primary" id="keynotes">
    <div class="container">
      <div class="row">
        <div class="col-lg-10 mx-auto text-center">
          <h2 class="section-heading text-white">Keynotes (1/5)</h2>
          <hr class="light my-4">
  
          <p class="text-faded" style="text-align: left; font-weight: bold; color: white; font-size: 26px;">
            Keynote 1
          </p>
          <br>
            <p class="text-faded" style="text-align: left; font-weight: bold; color: white; font-size: 24px;">
            Speaker:TBD
          </p>
         <!--   <div style="float:right; clear:both; top:30px;">
            <img src="images/changwenchen.jpg" style="height: 250px; border-radius: 10px;" />
          </div>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Speaker:
          </p>
  
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
           Changwen Chen
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Title:
          </p>
  
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
            Aesthetics Reasoning based on Multimodal LLM
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Time:
          </p>
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
         9:10-9:40, July 4, 2025
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Abstract:
          </p>
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
The rapid progress of generative art has democratized the creation of visually pleasing imagery. However, achieving genuine artistic impact, a nature that can resonate with viewers on a deeper, more meaningful level, requires a sophisticated aesthetic sensibility. This sensibility involves a multi-faceted reasoning process that extends beyond simple visual appeal, has often been overlooked by current computational models. This talk presents an initial endeavor to capture such a complex process by investigating how the reasoning capability of Multimodal LLMs (MLLMs) can be effectively elicited for aesthetic judgment. Our recent research reveals a critical challenge: MLLMs exhibit a tendency towards hallucinations during aesthetic reasoning, characterized by subjective opinions and unsubstantiated artistic interpretations. We shall demonstrate that these limitations can be overcome by employing an evidence-based, objective reasoning process, as substantiated by the proposed baseline algorithm, ArtCoT. MLLMs prompted by this principle produce multi-faceted and in-depth aesthetic reasoning that aligns significantly better with human judgment. These findings have direct applications in areas such as AI art tutoring and as reward models for generative art. We hope the proposed aesthetics reasoning framework can ultimately pave the way for constructing AI systems that can truly understand, appreciate, and contribute to artistic pieces just like the human aesthetic judgment.
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Biography:
          </p>
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
       Chang Wen Chen is currently Chair Professor of Visual Computing at The Hong Kong Polytechnic University. Before his current position, he served as Dean of the School of Science and Engineering at The Chinese University of Hong Kong, Shenzhen, from 2017 to 2020, and concurrently as Deputy Director at Peng Cheng Laboratory from 2018 to 2021. Previously, he was an Empire Innovation Professor at the State University of New York at Buffalo (SUNY) from 2008 to 2021 and the Allan Henry Endowed Chair Professor at the Florida Institute of Technology from 2003 to 2007. He received his BS degree from the University of Science and Technology of China in 1983, an MS degree from the University of Southern California in 1986, and his PhD degree from the University of Illinois at Urbana-Champaign (UIUC) in 1992.
          </p>
           <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
          He has served as Editor-in-Chief for IEEE Trans. Multimedia (2014-2016) and for IEEE Trans. Circuits and Systems for Video Technology (2006-2009). He has received many professional achievement awards, including ten (10) Best Paper Awards or Best Student Paper Awards, the prestigious Alexander von Humboldt Award in 2010, the SUNY Chancellor’s Award for Excellence in Scholarship and Creative Activities in 2016, the UIUC ECE Distinguished Alumni Award in 2019, and the ACM SIGMM Outstanding Technical Achievement Award in 2024. He is an IEEE Fellow, a SPIE Fellow, and a Member of Academia Europaea. 
          </p>
          -->
        </div>
      </div>
    </div>
  </section>

  <!-- second -->
    <section   id="keynotes-2">
      <div class="container">
        <div class="row">
          <div class="col-lg-10 mx-auto text-center">
            <h2 class="section-heading>Keynotes (2/5)</h2>
            <hr class="dark my-4">
    
            <p class="text-muted" style="text-align: left;font-weight: bold; font-size: 26px;">
              Keynote 2
            </p>
            <br>
               <p class="text-muted" style="text-align: left;font-weight: bold; font-size: 24px;">
            Speaker:TBD
          </p>
          <!--   
            <div style="float:right; clear:both; margin-left: 20px; margin-bottom: 20px;">
  <img src="images/caixinyuan.jpg" style="width: 180px; height: auto; border-radius: 10px;" />
</div>
            <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
              Speaker:
            </p>
    
            <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
              Xinyuan Cai
            </p>
            <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
              Title:
            </p>
    
            <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
              After the Dawn: Challenges and Strategies for AI-Driven Creative Education
            </p>
            <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
              Time:
            </p>
            <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
               10:40-11:10, July 4, 2025
            </p>
            <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
              Abstract:
            </p>
            <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
              With the rapid advancement of artificial intelligence technologies, creative education now stands at the threshold of a profound transformation. After the Dawn: Challenges and Strategies for AI-Driven Creative Education explores the deep impacts of AI on art and design education, while uncovering the underlying challenges and potential pathways for reform. This is not merely a response to technological intervention in teaching, but a redefinition of the very concept of “creativity.” </p>
               <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">  
            This talk unfolds across three dimensions. First, it reviews the practical applications of AI in artistic creation, design tools, and educational platforms in the current era, revealing its advantages in improving efficiency and expanding the boundaries of creative thinking. Taking large language models such as DeepSeek and ARTI Designer as examples, we observe how these tools are capable of generating stylistically distinct and logically coherent textual and visual outputs, becoming “new collaborators” in the creative process. Second, the lecture delves into the structural issues AI brings to creative education—such as the weakening of students’ originality, increased technological dependency, shifts in the role of educators, and imbalances in assessment systems. Meanwhile, we must also confront the cognitive biases and semantic inaccuracies exhibited by models like DeepSeek in educational contexts, underscoring the urgent need for ethical frameworks and critical literacy. Finally, the lecture proposes a set of systematic strategies and recommendations—ranging from curriculum redesign, AI ethics education, interdisciplinary collaboration mechanisms, to re-training programs for educators—to help higher education institutions build a more open, flexible, and sustainable AI-driven creative education system. </p>
               <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px"> 
            “After the Dawn” symbolizes not only the illumination brought by technology, but also the clarity and choices faced by educators and learners in the age of intelligence. This talk aims to inspire deep reflection on the future direction of creative education and to promote the formation of an innovative educational paradigm that embraces technology while upholding humanistic values. </p> 
            <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
              Biography:
            </p>
            <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
             Dr. Cai Xinyuan, Ph.D. Supervisor, Professor, Nationally Distinguished Expert.   </p>
                <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
             He is the Dean of the Design School at Huazhong University of Science and Technology, the Director of the Key Laboratory of Lighting Interactive Service and Technology, Ministry of Culture and Tourism, the Director of the Hubei Provincial Engineering Research Centre of Digital Light and Shadow Technology, the Chairman of ARTI Collaborative Platform of AI Art Education CHINA, and a member of the Teaching Steering Committee of Animation and Digital Media Major of the Ministry of Education.   </p>
              <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
                  Dr. Cai has long been engaged in teaching and research in the fields of digital media art theory and education, digital light and shadow art environment and landscape, artificial intelligence art and design. He has presided over more than 20 national key projects. He has successively completed many national, provincial and municipal major cultural and technological integration projects, such as the 70th anniversary of the National Day ‘Shining Hubei’ colourful car, Wuhan Yangtze River light show, and so on. He led the construction of ‘ARTI designer XL’ ARTI Art Design Supercomputing Platform to promote the development of artificial intelligence art education. His research and practice have promoted the deep integration of art, science and technology and culture, and played an important leading role in the field of design innovation in the era of intelligence. 
            </p>
 -->
    
          </div>
        </div>
      </div>
    </section>

  <!-- third -->
  <section  class="bg-primary" id="keynotes-3">
    <div class="container">
      <div class="row">
        <div class="col-lg-10 mx-auto text-center">
          <h2 class="section-heading text-white">Keynotes (3/5)</h2>
          <hr class="light my-4">

          <p class="text-faded" style="text-align: left; color: white; font-weight: bold; font-size: 26px;">
            Keynote 3
          </p>
          <br>
                <p class="text-faded" style="text-align: left; color: white; font-weight: bold; font-size: 24px;">
            Speaker:TBD
          </p>
          <!-- <div style="float:right; clear:both; top:30px;">
            <img src="images/jingdong.jpg" style="height: 200px; border-radius: 10px;" />
          </div>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Speaker:
          </p>

          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
            Jing Dong
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Title:
          </p>

          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
          Reflections and Outlook on Generative Artificial Intelligence ——From the Security and Ethics Perspective
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Time:
          </p>
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
          13:30-14:00, July 4, 2025
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Abstract:
          </p>
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
          Generative Artificial Intelligence (Generative AI), powered by Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs), is rapidly reshaping the landscape of artificial intelligence. State-of-the-art models such as GPT-4, DeepSeek, Claude, and DALL-E 3 demonstrate significant progress in generative capabilities, enabling breakthroughs in creative content synthesis, logical inference, automated decision-making, and domain-specific applications. However, the accelerated deployment of these systems has also exposed critical security vulnerabilities and ethical concerns, including the risks of misuse, deepfakes, phishing scams, data privacy breaches, and model security. It has raised unexpected concerns from individuals, organizations, communities and even nations. As Generative AI continues to evolve and integrate into various applications and sectors, the need for robust mechanisms to ensure the safety, trustworthiness, and ethical use of generative models has become increasingly urgent.  This talk will focus on security and ethics threats, state-of-the-art solutions and future challenges of the generative AI , especially for visual information.
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Biography:
          </p>
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
      Dr. Jing Dong is currently a Full Professor/Researcher in the National Laboratory of Pattern Recognition in the Institute of Automation, Chinese Academy of Sciences (CASIA). She is a senior member of IEEE/CCF/CSIG. Her research interests include pattern recognition, image processing and image forensics. She has published more than 100 academic papers and chaired in many major national scientific projects and played a leading role in several national and international technical conferences. 
          </p>
              <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
      She served as the IEEE Biometric Council Beijing Chapter Chair since 2019 and the IEEE R10 ExCom member since 2017. She was also the IEEE SPS Membership Development Director from 2022 to 2024. 
          </p>
              <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
      She was awarded with the IBM Faculty Award (2016) and the ICPR Best Scientific Paper Award (2018), the CAAI Outstanding Individual Member Award (2019), the CSIG Outstanding Female Young Scientist Award (2020) , the CSIG Science and Technology Award (2021) 、the Wu Wenjun Artificial Intelligence Science and Technology Award (2021) and the CAI Innovation Award (1st Prize,2022) for her excellent contribution for the technical innovation and leadership for the community.
          </p>
 -->

        </div>
      </div>
    </div>
  </section> 

  <!-- fourth -->
   <section  id="keynotes-4">
    <div class="container">
      <div class="row">
        <div class="col-lg-10 mx-auto text-center">
          <h2 class="section-heading">Keynotes (4/5)</h2>
          <hr class="dark my-4">

          <p class="text-muted" style="text-align: left; font-weight: bold;font-size: 26px;">
            Keynote 4
          </p>
          <br>
                <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
            Speaker:TBD
          </p>
     <!--   <div style="float:right; clear:both; top:30px;">
            <img src="images/haonancheng.jpg" style="height: 250px; border-radius: 10px;" />
          </div>
          <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
            Speaker:
          </p>

          <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
         Haonan Cheng
          </p>
          <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
            Title:
          </p>

          <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
          Audio Computing in Multimedia Intelligence: Methods, Applications, and Prospects
          </p>
          <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
            Time:
          </p>
          <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
            14:50-15:20, July 4, 2025
          </p>
          <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
            Abstract:
          </p>
          <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
           Audio computing technology in multimedia intelligence, as an intersection of artificial intelligence, physical acoustics and art, is undergoing a paradigm shift from traditional signal analysis to deep semantic understanding. In recent years, the boundaries of generative AI combined with audio continue to expand. The audio computing is reshaping the sensory dimensions of human-computer interaction from traditional audio recording to personalized music creation, and from ambient sound simulation to cross-modal content generation, which poses new security risks. This report focuses on the key methods, typical applications, and future trends of audio computing, with an emphasis on its critical role in intelligent creation, immersive experience, and content security.
          </p>
          <p class="text-muted" style="text-align: left; font-weight: bold; font-size: 24px;">
            Biography:
          </p>
          <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
      Haonan Cheng, associate researcher of the State Key Laboratory of Media Convergence and Communication, Communication University of China, mainly focuses on audio information processing, audio-visual cross modal generation and forgery detection.   </p>
     <p class="text-muted" style="text-align: left; font-weight: light; font-size: 18px">
          She became the first technical expert in China to be awarded the Asia-Pacific Young Engineer Prize by ABU in 2024, and was selected for the Beijing National Governance and Young Talent Cultivation Program in 2025. In recent years, she has published more than 40 SCI/EI papers in IEEE TOG, TIFS, TASLP, SIGGRAPH, IEEE VR, IJCAI, AAAI, ACM MM, etc. She has been authorized 2 national invention patents, and won the Excellent Paper Award in the 5th CSIG China Media Forensics and Security Conference, and Best Poster Paper Award in the 20th International Forum on Digital Multimedia Communications. She was funded by more than 10 projects, including National Natural Science Foundation of China, National Key R&D Program, National Social Science Foundation of China, and Medium and Long-term Science and Technology Program for Radio, Television and Audiovisual Network, etc. She serves as a member of the Multimedia Specialized Committee of the Chinese Society of Image and Graphics, the Program Chair of the International Forum on Digital Multimedia Communications, the Forum Chair of the China Multimedia Conference, and the Session Chair of ACM MM and other international conferences.

          </p>
-->
        </div>
      </div>
    </div>
  </section> 

  <!-- fifth -->
  <section  class="bg-primary" id="keynotes-5">
    <div class="container">
      <div class="row">
        <div class="col-lg-10 mx-auto text-center">
          <h2 class="section-heading  text-white">Keynotes (5/5)</h2>
          <hr class="light my-4">

          <p class="text-faded" style="text-align: left; color: white; font-weight: bold; font-size: 26px;">
            Keynote 5
          </p>
          <br>
                <p class="text-faded" style="text-align: left; color: white; font-weight: bold; font-size: 24px;">
            Speaker:TBD
          </p>
        <!--    <div style="float:right; clear:both; top:30px;">
            <img src="images/Terence Broad.jpg" style="height: 200px; border-radius: 10px;" />
          </div>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Speaker:
          </p>

          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
           Terence Broad
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Title:
          </p>

          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
            Explaining AI through artistic practice
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Time:
          </p>
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
           16:10-16:40, July 4, 2025
          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Abstract:
          </p>
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
         Generative neural networks produce media through a complex fabric of computation, contingent on large scraped datasets, where features and representations get encoded into the weights of unfathomably large data arrays, which in turn are enmeshed through complex chains of computation. The ease and realism through which this generated media is mass-produced and its almost uncanny flawlessness makes it easy to forget the complex computational contingencies that produce it. This talk will show how through the artistic practice of making targeted interventions to inputs, weights, training and inference of generative neural networks, artists are able to make critical works that reveal to us otherwise unseen aspects of these models, where the artworks themselves present new ways of understanding and making sense of these unfathomably complex computational systems. 

          </p>
          <p class="text-white" style="text-align: left; font-weight: bold; font-size: 24px;">
            Biography:
          </p>
          <p class="text-white" style="text-align: left; font-weight: light; font-size: 18px">
           Terence Broad is an artist and researcher working in London. He is a Senior Lecturer at the UAL Creative Computing Institute and has recently completed a PhD at Goldsmiths in generative AI. His art and research have been presented internationally: at conferences and journals such as SIGGRAPH, Leonardo, NeurIPS, and ICCC; and museums such as The Whitney Museum of American Art, Garage Museum of Contemporary Art, Ars Electronica, The Barbican and The Whitechapel Gallery. In 2019 He won the Grand Prize in the ICCV Computer Vision Art Gallery. His work is in the city of Geneva’s contemporary art collection.
          </p>
-->

        </div>
      </div>
    </div>
  </section> 


  <section  id="program">
    <div class="container">
      <div class="row">
        <div class="col-lg-10 mx-auto text-center">
          <h2 class="section-heading">Conference Program</h2>
          <hr class="dark my-4">
          <p style="font-size: 2em; font-weight: bold;">TBD</p>
          <!--<img src="images/aiart2025_program.jpg" style="max-width: 100%;" />-->
        </div>
      </div>
    </div>
  </section>


<section class="bg-primary" id="ps">
  <div class="container">
    <div class="row">
      <div class="col-lg-10 mx-auto text-center">
        <h2 class="section-heading  text-white">Technical Program Committee (Tentative)</h2>
        <hr class="light my-4">

        <ul class="text-faded"
            style="text-align:left; color: white; font-size:18px; line-height:1.8; margin:0; padding-left:1.2rem; list-style:disc;">
          <li>Ajay Kapur, California Institute of the Arts, USA</li>
          <li>Alan Chamberlain, University of Nottingham, Nottingham</li>
          <li>Alexander Lerch, Georgia Institute of Technology, USA</li>
          <li>Alexander Pantelyat, Johns Hopkins University, USA</li>
          <li>Bahareh Nakisa, Deakin University, Australia</li>
          <li>Baoqiang Han, China Conservatory of Music, China</li>
          <li>Baoyang Chen, Central Academy of Fine Arts, China</li>
          <li>Beici Liang, Tencent Music Entertainment Group, China</li>
          <li>Bing Li, King Abdullah University of Science and Technology, Saudi Arabia</li>
          <li>Björn W. Schuller, Imperial College London, UK</li>
          <li>Bob Sturm, KTH Royal Institute of Technology, Sweden</li>
          <li>Borou Yu, Harvard University, USA</li>
          <li>Carlos Castellanos, Rochester Institute of Technology, USA</li>
          <li>Changsheng Xu, Institute of Automation, Chinese Academy of Sciences, China</li>
          <li>Dongmei Jiang, Northwestern Polytechnical University, China</li>
          <li>Emma Young, BBC, UK</li>
          <li>Gerui Wang, Stanford University, USA</li>
          <li>Gus Xia, New York University Shanghai, China &amp; Mohamed bin Zayed University of Artificial Intelligence, United Arab Emirates</li>
          <li>Haifeng Li, Harbin Institute of Technology, China</li>
          <li>Haipeng Mi, Tsinghua University, China</li>
          <li>Hongxun Yao, Harbin Institute of Technology, China</li>
          <li>Jesse Engel, Google, USA</li>
          <li>Jia Jia, Tsinghua University, China</li>
          <li>Jiajian Min, Harvard University, USA</li>
          <li>Jianyu Fan, Microsoft, Canada</li>
          <li>Jing Wang, Beijing Institute of Technology, China</li>
          <li>John See, Multimedia University, Malaysia</li>
          <li>Juan Huang, Johns Hopkins University, USA</li>
          <li>Junping Zhang, Fudan University, China</li>
          <li>Kejun Zhang, Zhejiang University, China</li>
          <li>Ke Lv, University of Chinese Academy of Sciences, China</li>
          <li>Kenneth Fields, Central Conservatory of Music, China</li>
          <li>Lai-Kuan Wong, Multimedia University, Malaysia</li>
          <li>Lamtharn Hanoi Hantrakul, ByteDance, USA</li>
          <li>Lei Xie, Northwestern Polytechnical University, China</li>
          <li>Li Zhou, China University of Geosciences (Wuhan), China</li>
          <li>Lin Gan, Tianjin University, China</li>
          <li>Long Ye, China University of Communication, China</li>
          <li>Maosong Sun, Tsinghua University, China</li>
          <li>Mei Han, Ping An Technology Art institute, USA</li>
          <li>Mengjie Qi, China Conservatory of Music, China</li>
          <li>Ming Zhang, Nanjing Art College, China</li>
          <li>Mohammad Naim Rastgoo, Queensland University of Technology, Australia</li>
          <li>Na Qi, Beijing University of Technology, China</li>
          <li>Nick Bryan-Kinns, Queen Mary University of London, UK</li>
          <li>Nina Kraus, Northwestern University, USA</li>
          <li>Pengtao Xie, University of California, San Diego, USA</li>
          <li>Philippe Pasquier, Simon Fraser University, Canada</li>
          <li>Qin Jin, Renmin University, China</li>
          <li>Qiuqiang Kong, ByteDance, China</li>
          <li>Rebecca Fiebrink, University of London, UK</li>
          <li>Rick Taube, University of Illinois at Urbana-Champaign, USA</li>
          <li>Roger Dannenberg, Carnegie Mellon University, USA</li>
          <li>Rongfeng Li, Beijing University of Posts and Telecommunications, China</li>
          <li>Rui Wang, Institute of Information Engineering, Chinese Academy of Sciences, China</li>
          <li>Ruihua Song, Renmin University, China</li>
          <li>Shangfei Wang, University of Science and Technology of China, China</li>
          <li>Shasha Mao, Xidian University, China</li>
          <li>Shiguang Shan, Institute of Computing Technology, Chinese Academy of Sciences, China</li>
          <li>Shiqi Wang, City University of Hong Kong, China</li>
          <li>Shun Kuremoto, Uchida Yoko Co.,Ltd, Japan</li>
          <li>Si Liu, Beihang University, China</li>
          <li>Simon Lui, Huawei Technologies Co., Ltd, China</li>
          <li>Tiange Zhou, NetEase Cloud Music, China</li>
          <li>Weibei Dou, Tsinghua University, China</li>
          <li>Weiming Dong, Institute of Automation, Chinese Academy of Sciences, China</li>
          <li>Wei-Ta Chu, National Chung Cheng University, Taiwan, China</li>
          <li>Wei Li, Fudan University, China</li>
          <li>Weiwei Zhang, Dalian Maritime University, China</li>
          <li>Wei Zhong, Communication University of China, China</li>
          <li>Wen-Huang Cheng, National Chiao Tung University, Taiwan, China</li>
          <li>Wenli Zhang, Beijing University of Technology, China</li>
          <li>Xi Shao, Nanjing University of Posts and Telecommunications, China</li>
          <li>Xiaojing Liang, NetEase Cloud Music, China</li>
          <li>Xiaopeng Hong, Harbin Institute of Technology, China</li>
          <li>Xiaoyan Sun, University of Science and Technology of China, China</li>
          <li>Xiaoying Zhang, China Rehabilitation Research Center, China</li>
          <li>Xihong Wu, Peking University, China</li>
          <li>Xinfeng Zhang, University of Chinese Academy of Sciences, China</li>
          <li>Xu Tan, Microsoft Research Asia, China</li>
          <li>Yanchao Bi, Beijing Normal University, China</li>
          <li>Yi Qin, Shanghai Conservatory of Music, China</li>
          <li>Ying-Qing Xu, Tsinghua University, China</li>
          <li>Yirui Wu, Hohai University, China</li>
          <li>Yuanchun Xu, Xiaoice, China</li>
          <li>Zhiyao Duan, University of Rochester, USA</li>
        </ul>

      </div>
    </div>
  </div>
</section>


<section  id="ppl">
  <div class="container">
    <div class="row">
      <div class="col-lg-12 text-center">
        <h2 class="section-heading">Organizing Team</h2>
        <hr class="dark my-4">
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row">

      <!-- Luntian Mou -->
      <div class="col-lg-6 col-md-8 text-center">
        <div class="service-box mt-5 mx-auto">
          <img class="mb-3" src="images/Luntian_Mou.jpeg" style="height: 200px; border-radius: 20px;" />

          <h5 class="mb-3">
            <a target="_blank" rel="noopener noreferrer" class="text-muted" style="text-decoration: none;">
              Luntian Mou
            </a>
          </h5>

          <p class="text-muted mb-0" style="font-size: 0.9em;">Beijing University of Technology</p>
          <p class="text-muted mb-0" style="font-size: 0.9em;">Beijing, China</p>
          <a href="mailto:ltmou@bjut.edu.cn" class="text-muted" style="text-decoration:none;">
            <p class="mb-0" style="font-size: 0.9em;">ltmou@bjut.edu.cn</p>
          </a>
          <br>

          <p class="text-muted mb-0" style="font-size: 0.9em;" align="left">
            Dr. Luntian Mou is an Associate Professor with the School of Information Science and Technology, Beijing Institute of Artificial Intelligence (BIAI), Beijing University of Technology. He received the Ph.D. degree in computer science from the University of Chinese Academy of Sciences, China in 2012. He served as a Postdoctoral Fellow at Peking University, from 2012 to 2014. And he was a Visiting Scholar with the University of California, Irvine, from 2019 to 2020. He initiated the IEEE Workshop on Artificial Intelligence for Art Creation (AIART) in 2019, and has organized the workshop annually ever since. His current research interests include artificial intelligence, machine learning, multimedia computing, affective computing, and brain-like computing. He is the recipient of Beijing Municipal Science and Technology Advancement Award, IEEE Outstanding Contribution to Standardization Award, and AVS Outstanding Contribution on 15th Anniversary Award. He serves as a guest editor for Machine Intelligence Research, and a reviewer for many important international journals and conferences such as TIP, TAFFC, TCSVT, TITS, AAAI, etc. And he serves as a Co-Chair of System subgroup in AVS workgroup. He is a Senior Member of IEEE and CCF, and a Member of ACM, CAAI, and CSIG, and an Expert of MPEG China.
          </p>
        </div>
      </div>

      <!-- Feng Gao -->
      <div class="col-lg-6 col-md-8 text-center">
        <div class="service-box mt-5 mx-auto">
          <img class="mb-3" src="images/Feng_Gao.jpeg" style="height: 200px; border-radius: 20px;" />

          <h5 class="mb-3">
            <a target="_blank" rel="noopener noreferrer" class="text-muted" style="text-decoration: none;">
              Feng Gao
            </a>
          </h5>

          <p class="text-muted mb-0" style="font-size: 0.9em;">Peking University</p>
          <p class="text-muted mb-0" style="font-size: 0.9em;">Beijing, China</p>
          <a href="mailto:gaof@pku.edu.cn" class="text-muted" style="text-decoration:none;">
            <p class="mb-0" style="font-size: 0.9em;">gaof@pku.edu.cn</p>
          </a>
          <br>

          <p class="text-muted mb-0" style="font-size: 0.9em;" align="left">
            Dr. Feng Gao is an Assistant Professor with the School of Arts, Peking University. He has long researched in the disciplinary fields of AI and art, especially in AI painting. He co-initiated the international workshop of AIART. Currently, he is also enthusiastic in virtual human. He has demonstrated his AI painting system, called Daozi, in several workshops and drawn much attention.
          </p>
        </div>
      </div>

      <!-- Kejun Zhang -->
      <div class="col-lg-6 col-md-8 text-center">
        <div class="service-box mt-5 mx-auto">
          <img class="mb-3" src="images/Kejun_Zhang.jpg" style="height: 200px; border-radius: 20px;" />

          <h5 class="mb-3">
            <a target="_blank" rel="noopener noreferrer" class="text-muted" style="text-decoration: none;">
              Kejun Zhang
            </a>
          </h5>

          <p class="text-muted mb-0" style="font-size: 0.9em;">Zhejiang University</p>
          <p class="text-muted mb-0" style="font-size: 0.9em;">Hangzhou, China</p>
          <a href="mailto:zhangkejun@zju.edu.cn" class="text-muted" style="text-decoration:none;">
            <p class="mb-0" style="font-size: 0.9em;">zhangkejun@zju.edu.cn</p>
          </a>
          <br>

          <p class="text-muted mb-0" style="font-size: 0.9em;" align="left">
            Dr. Kejun Zhang is a Professor with Zhejiang University, joint PhD supervisor on Design and Computer Science, Dean of Department of Industrial Design at College of Computer Science of Zhejiang University. He received his PhD degree from College of Computer Science and Technology, Zhejiang University in 2010. From 2008 to 2009, He was a visiting research scholar of University of Illinois at Urbana-Champaign, USA. In June 2013, he became a faculty of the College of Computer Science and Technology at Zhejiang University. His current research interests include Affective Computing, Design Science, Artificial Intelligence, Multimedia Computing and the understanding, modelling and innovation design of products and social management by computational means. He is now the PI of National Science Foundation of China, Co-PI of National Key Research and Development Program of China, and PIs of ten more other research programs. He has authored 4 books, more than 40 scientific papers.
          </p>
        </div>
      </div>

      <!-- Haonan Cheng -->
      <div class="col-lg-6 col-md-8 text-center">
        <div class="service-box mt-5 mx-auto">
          <img class="mb-3" src="images/haonancheng.jpg" style="height: 200px; border-radius: 20px;" />

          <h5 class="mb-3">
            <a target="_blank" rel="noopener noreferrer" class="text-muted" style="text-decoration: none;">
              Haonan Cheng
            </a>
          </h5>

          <p class="text-muted mb-0" style="font-size: 0.9em;">Communication University of China</p>
          <p class="text-muted mb-0" style="font-size: 0.9em;">Beijing, China</p>
          <!-- 这里原来少了 mailto:，我顺便修正 -->
          <a href="mailto:haonancheng@cuc.edu.cn" class="text-muted" style="text-decoration:none;">
            <p class="mb-0" style="font-size: 0.9em;">haonancheng@cuc.edu.cn</p>
          </a>
          <br>

          <p class="text-muted mb-0" style="font-size: 0.9em;" align="left">
            Dr. Haonan Cheng is a Professor with the State Key Laboratory of Media Convergence and Communication, Communication University of China, mainly focuses on audio information processing, audio-visual cross modal generation and forgery detection. She became the first technical expert in China to be awarded the Asia-Pacific Young Engineer Prize by ABU in 2024, and was selected for the Beijing National Governance and Young Talent Cultivation Program in 2025. In recent years, she has published more than 50 SCI/EI papers in IEEE TOG, TIFS, TASLP, SIGGRAPH, IEEE VR, IJCAI, AAAI, ACM MM, etc. She has been authorized 2 national invention patents, and won the Excellent Paper Award in the 5th CSIG China Media Forensics and Security Conference, and Best Poster Paper Award in the 20th International Forum on Digital Multimedia Communications. She was funded by more than 10 projects, including National Natural Science Foundation of China, National Key R&amp;D Program, National Social Science Foundation of China, and Medium and Long-term Science and Technology Program for Radio, Television and Audiovisual Network, etc. She serves as a member of the Multimedia Specialized Committee of the Chinese Society of Image and Graphics, the Program Chair of the International Forum on Digital Multimedia Communications, the Forum Chair of the China Multimedia Conference, and the Session Chair of ACM MM and other international conferences.
          </p>
        </div>
      </div>

      <!-- Ambarish Natu -->
      <div class="col-lg-6 col-md-8 text-center">
        <div class="service-box mt-5 mx-auto">
          <img class="mb-3" src="images/Ambarish_Natu.jpg" style="height: 200px; border-radius: 20px;" />

          <h5 class="mb-3">
            <a target="_blank" rel="noopener noreferrer" class="text-muted" style="text-decoration: none;">
              Ambarish Natu
            </a>
          </h5>

          <p class="text-muted mb-0" style="font-size: 0.9em;">Australian Government</p>
          <p class="text-muted mb-0" style="font-size: 0.9em;">Australian Capital Territory, Australia</p>
          <a href="mailto:ambarish.natu@gmail.com" class="text-muted" style="text-decoration:none;">
            <p class="mb-0" style="font-size: 0.9em;">ambarish.natu@gmail.com</p>
          </a>
          <br>

          <p class="text-muted mb-0" style="font-size: 0.9em;" align="left">
            Dr. Ambarish Natu is with the Australian Government. After graduating from University of New South Wales, Sydney, Ambarish has held positions as a visiting researcher in Italy and Taiwan, worked for industry in United Kingdom and the United States of America and for the past ten years has been working in the Australian Government. For the past 17 years, Ambarish has led the development of five international standards under the auspices of the International Standards Organization (ISO) popularly known as JPEG (Joint Photographic Experts Group). He is the recipient of the ISO/IEC certificate for contributions to technology standards. Ambarish is highly active in the area of international standardization and voicing Australian concerns in the area of JPEG and MPEG (Motion Pictures Experts Group) standardization. He previously initiated an effort in the area of standardization relating to Privacy and Security in the Multimedia Context both within JPEG and MPEG standard bodies. In 2015, Ambarish was the recipient of the prestigious Neville Thiele Award and the Canberra Professional Engineer of the Year by Engineers Australia. Ambarish currently works as an ICT Specialist for the Australian Government. Ambarish is a Fellow of the Australian Computer Society and Engineers Australia. Ambarish also serves on the IVMSP TC and the Autonomous Systems Initiative of the IEEE Signal Processing Society. Ambarish has also been General Chair of DICTA 2018, ICME 2023 and TENSYMP 2023 in the past. Ambarish has keen interest in next generation data and analytics technologies that will change the course of the way we interact with in the world.
          </p>
        </div>
      </div>

      <!-- Gerui Wang -->
      <div class="col-lg-6 col-md-8 text-center">
        <div class="service-box mt-5 mx-auto">
          <img class="mb-3" src="images/geruiwang.jpg" style="height: 200px; border-radius: 20px;" />

          <h5 class="mb-3">
            <a target="_blank" rel="noopener noreferrer" class="text-muted" style="text-decoration: none;">
              Gerui Wang
            </a>
          </h5>

          <p class="text-muted mb-0" style="font-size: 0.9em;">Stanford University</p>
          <p class="text-muted mb-0" style="font-size: 0.9em;">California, USA</p>
          <!-- 这里原来 mailto 写错了，我顺便修正 -->
          <a href="mailto:grwang@stanford.edu" class="text-muted" style="text-decoration:none;">
            <p class="mb-0" style="font-size: 0.9em;">grwang@stanford.edu</p>
          </a>
          <br>

          <p class="text-muted mb-0" style="font-size: 0.9em;" align="left">
            Dr. Gerui Wang is a Lecturer at Stanford University Center for East Asian Studies, where she teaches classes on contemporary art, AI and posthumanism. Her research interests span arts, public policy, environment, and emerging technologies. She is a member of the Alan Turing Institute AI&amp;Arts Research Group. With her background in art history, she has published in the Journal of Chinese History and Newsletter for International China Studies. Gerui's book Sustaining Landscapes: Governance and Ecology in Chinese Visual Culture is forthcoming in 2025. Her research briefs on AI, robotics, media, and society are frequently featured in public venues including Forbes, Alan Turing Institute's AI and Art Forum, Asia Times, and South China Morning Post. Gerui holds a doctorate in art history from the University of Michigan.
          </p>
        </div>
      </div>

      <!-- Ling Fan -->
      <div class="col-lg-6 col-md-8 text-center">
        <div class="service-box mt-5 mx-auto">
          <img class="mb-3" src="images/Ling_Fan.jpg" style="height: 200px; border-radius: 20px;" />

          <h5 class="mb-3">
            <a target="_blank" rel="noopener noreferrer" class="text-muted" style="text-decoration: none;">
              Ling Fan
            </a>
          </h5>

          <p class="text-muted mb-0" style="font-size: 0.9em;">Tezign.com</p>
          <p class="text-muted mb-0" style="font-size: 0.9em;">Tongji University Design Artificial Intelligence Lab</p>
          <p class="text-muted mb-0" style="font-size: 0.9em;">Shanghai, China</p>
          <a href="mailto:lfan@tongji.edu.cn" class="text-white" style="text-decoration:none;">
            <p class="mb-0" style="font-size: 0.9em;">lfan@tongji.edu.cn</p>
          </a>
          <br>

          <p class="text-muted mb-0" style="font-size: 0.9em;" align="left">
            Dr. Ling Fan is a Scholar and Entrepreneur to bridge machine intelligence with creativity. He is the founding chair and professor of Tongji University Design Artificial Intelligence Lab. Before, he held teaching position at the University of California at Berkeley and China Central Academy of Fine Arts. Dr. Fan co-founded Tezign.com, a leading technology start-up with the mission to build digital infrastructure for creative contents. Tezign is backed by top VCs like Sequoia Capital and Hearst Ventures. Dr. Fan is a World Economic Forum Young Global Leader, an Aspen Institute China Fellow, and Youth Committee member at the Future Forum. He is also a member of IEEE Global Council for Extended Intelligence. Dr. Fan received his doctoral degree from Harvard University and master's degree from Princeton University. He recently published From Universality of Computation to the Universality of Imagination, a book on how machine intelligence would influence human creativity.
          </p>
        </div>
      </div>

      <!-- Terence Broad -->
      <div class="col-lg-6 col-md-8 text-center">
        <div class="service-box mt-5 mx-auto">
          <img class="mb-3" src="images/Terence Broad.jpg" style="height: 200px; border-radius: 20px;" />

          <h5 class="mb-3">
            <a target="_blank" rel="noopener noreferrer" class="text-muted" style="text-decoration: none;">
              Terence Broad
            </a>
          </h5>

          <p class="text-muted mb-0" style="font-size: 0.9em;">University of the Arts London</p>
          <p class="text-muted mb-0" style="font-size: 0.9em;">London, The United Kingdom</p>
          <a href="mailto:t.broad@arts.ac.uk" class="text-muted" style="text-decoration:none;">
            <p class="mb-0" style="font-size: 0.9em;">t.broad@arts.ac.uk</p>
          </a>
          <br>

          <p class="text-muted mb-0" style="font-size: 0.9em;" align="left">
            Dr. Terence Broad is an Artist and Researcher working in London. He is a Senior Lecturer at the UAL Creative Computing Institute and has recently completed a PhD at Goldsmiths in generative AI. His art and research have been presented internationally: at conferences and journals such as SIGGRAPH, Leonardo, NeurIPS, and ICCC; and museums such as The Whitney Museum of American Art, Garage Museum of Contemporary Art, Ars Electronica, The Barbican and The Whitechapel Gallery. In 2019 He won the Grand Prize in the ICCV Computer Vision Art Gallery. His work is in the city of Geneva’s contemporary art collection.
          </p>
        </div>
      </div>

    </div>
  </div>
</section>




 <section class="bg-primary" id="MIR">
  <div class="container">
    <div class="row">
      <div class="col-lg-10 mx-auto text-center">

        <h2 class="section-heading text-white">Partners</h2>
        <hr class="light my-4">

        <!-- Partner title -->
        <h5 class="section-heading text-white" style="text-align:left; line-height:1.8">
          <strong>Partner1: Machine Intelligence Research</strong>
        </h5>

        <!-- Description -->
        <div class="text-faded" style="text-align:left; color:white; font-size:18px; line-height:1.8">
         Machine Intelligence Research (IF:8.7, JCR Q1), published by Springer, and sponsored by Institute of Automation, Chinese Academy of Sciences, is formally released in 2022. The journal publishes high-quality papers on original theoretical and experimental research in artificial intelligence, targets special issues on emerging topics and specific subjects, and strives to bridge the gap between theoretical research and practical applications. The journal has been indexed by ESCI, EI, Scopus, CSCD, etc.
        </div>

        <!-- Topics -->
        <div class="text-faded" style="text-align:left; color:white; font-size:18px; line-height:1.8; margin-top:15px">
         Topics of Machine Intelligence Research include: AI Fundamentals, Brain-Inspired Intelligence, Pattern Recognition & Machine Learning, Machine Vision, Speech and Language Processing, Embodied Intelligence and Robotics, Knowledge Management & Data Mining, and Applications of Machine Intelligence.
        </div>

        <!-- List -->
        <ul style="color:white; text-align:left;color:white; margin-top:20px">

          <li>
            <div class="text-faded" style="font-size:18px; color:white;line-height:1.8">
              <strong>MIR official websites:</strong>
              <ul>
                <li>
                  <a href="https://www.springer.com/journal/11633" target="_blank">
                    https://www.springer.com/journal/11633
                  </a>
                </li>
                <li>
                  <a href="https://www.mi-research.net" target="_blank">
                    https://www.mi-research.net
                  </a>
                </li>
              </ul>
            </div>
          </li>

          <li>
            <div class="text-faded" style="font-size:18px;color:white; line-height:1.8">
             <strong>MIR Editors-in-Chief </strong>
              <ul>
                <li>Tan Tieniu, Institute of Automation, Chinese Academy of Sciences</li>
              </ul>
            </div>
          </li>

          <li>
            <div class="text-faded" style="font-size:18px;color:white; line-height:1.8">
               <strong>MIR Associate Editors-in-Chief</strong>
              <ul>
                <li>Yike Guo, Hong Kong University of Science and Technology, China</li>
                <li>Brian C. Lovell, The University of Queensland, Australia</li>
                <li>Danilo P. Mandic, Imperial College London, UK</li>
                <li>Liang Wang, Chinese Academy of Sciences, China</li>
              </ul>
            </div>
          </li>

        </ul>

        <!-- Image -->
        <div style="text-align:center; margin-top:30px">
          <img src="images/MIR1.png" alt="Machine Intelligence Research" 
               style="max-width:100%; height:auto;">
        </div>
         <br> <br>
          <!-- Partner title -->
        <h5 class="section-heading text-white" style="text-align:left; line-height:1.8">
          <strong>Partner2: The Transactions on Artificial Intelligence </strong>
        </h5>

        <!-- Description -->
        <div class="text-faded" style="text-align:left; color:white; font-size:18px; line-height:1.8">
         The Transactions on Artificial Intelligence (TAI) is a peer-reviewed, open-access journal dedicated to advancing trustworthy, explainable, and human-centered AI. The journal highlights emerging frontiers—including generative AI, autonomous systems, AI safety, and data-centric intelligence—while maintaining strong coverage of core AI theory and methodologies.
        </div>

        <!-- List -->
        <ul style="color:white; text-align:left; margin-top:20px">

          <li>
            <div class="text-faded" style="font-size:18px; color:white;line-height:1.8">
              <strong>TAI official websites:</strong>
              <ul>
                <li>
                  <a href="https://www.sciltp.com/journals/tai" target="_blank">
                    https://www.sciltp.com/journals/tai
                  </a>
                </li>
              </ul>
            </div>
          </li>
          <li>
            <div class="text-faded" style="font-size:18px;color:white; line-height:1.8">
             <strong>TAI Editors-in-Chief </strong>
              <ul>
                <li>Prof. Dapeng Oliver Wu, City University of Hong Kong, Hong Kong</li>
              </ul>
            </div>
          </li>


        <!-- Image -->
   <div style="text-align:center; margin-top:30px">
  <img class="mb-3"
       src="images/TAI.jpg"
       alt="TAI"
       style="height:auto; width:100%; max-width:400px; border-radius:20px;" />
  <br>
</div>

      </div>
    </div>
  </div>
</section>


  <section  id="sponsorship">
    <div class="container">
      <div class="row">
        <div class="col-lg-10 mx-auto text-center">
          <h2 class="section-heading">Sponsorship</h2>
          <hr class="dark my-4">

            <h5 class="section-heading" style="text-align: left; line-height: 1.8">
            <p style="font-size: 1.5em; text-align: center; margin-top: 20px;">
          TBD
        </p>
         

       <!--      <div class="text-muted mb-0" style="text-align: left;color: black;font-size: 18px;line-height: 1.8">

              <strong>Platinum Level (RMB￥100,000)</strong><br>
              - Large booths (size TBD)<br>
              - Invitation to give an industry keynote speech<br>
              - Logo on AIART 2024 official website with description and link to sponsor website<br>
              - Logo on workshop handbook and presentation material (under Platinum Level)<br>
              - One on one negotiation for special requirements.<br><br>

              <strong>Gold Level (RMB￥50,000)</strong><br>
              - Medium booths (size TBD)<br>
              - Participation in related industry panel<br>
              - Logo on AIART 2024 official website with short description and link to sponsor website<br>
              - Logo on workshop handbook and presentation material (under Gold Level)<br>
              - One on one negotiation for special requirements.<br><br>

              <strong>Silver Level (RMB￥20,000)</strong><br>
              - Small booths (size TBD)<br>
              - Logo on AIART 2024 official website with link to sponsor website<br>
              - Logo on workshop handbook and presentation material (under Silver Level)<br><br>

            </div> -->

         <!--       </h5>
          <br><br>
        <a>
  <img src="images/douyin_logo1.png" style="width: 100%; max-width: 400px; height: auto; display: block; margin: 0 auto;" />
</a>

          <br><br><br>


          <h5 class="section-heading text-white" style="text-align: left; line-height: 1.8">

               <div class="text-muted mb-4" style="text-align: justify; color: black; font-size: 18px; line-height: 1.8; font-weight: normal;">
              Douyin (抖音), is a platform that helps users express themselves and record their good life. Douyin is leading the short-video app universe in China with more than 755 million monthly active users (MAU) and continues to grow at a high rate. Douyin covers a wide range of video content, including technology, art, aesthetics, daily life, etc., and is committed to enriching the life of every user. <br><br>

              <!-- Tezign has raised the D1 round of financing and become the only Contech unicorn enterprise with a
              valuation of more than US $1 billion. Tezign is backed by world recognized investors including Temasek,
              Sequoia Capital, Hearst Ventures, among others. Tezign has partnered with more than 200 medium to large
              enterprises such as Alibaba, Unilever, ByteDance, PepsiCo, Shiseido, P&G, Starbucks, McDonald's, Heinz,
              Mars, Budweiser, Adidas, Xtep, Ubras, Lenovo, Midea, Tencent, L'Oreal, Danone, Porsche, Audi, Volvo,
              Aptar, Bosch, Stanley Black & Decker etc to upgrade their content strategies. It has produced more than
              150,000 creative content assets and formed a one hundred million level content asset management scale.
              Tezign's content ecosystem has gathered more than 50,000 content creators. <br><br>

              Tezign was a National Industrial Design Center issued by the Ministry of industry and information
              technology, awarded as TOP.1 in China in the list of The Information 50 startups, Fast Company top 50 of
              China's best innovative companies, Forbes High Growth Gazelle, Forbes China Top 10 intelligent design
              enterprises, Hurun Group List of Global Unicorn, and was named by Forrester, a leading independent global
              technology and market research company, in the Research Report "Now Tech: Marketing Resource Management,
              Q12022" (MRM) as the only MRM vendor in the contech segment Asia Pacific. <br><br>

              On 6th-7th May 2023, Tezign will launch the AIGC Builder and Creator Conference in Shanghai, to create
              maximum two-way interaction among AIGC creators and builders in various quality forms. Stay tuned by
              following the official Wechat account: Who is AIGC. <br> -->
            </div>

          </h5>
        </div>
      </div>
    </div>
  </section>

  
 <section class="bg-primary" id="Gallery">
  <div class="container">
    <div class="row">
      <div class="col-lg-10 mx-auto text-center">
        <h2 class="section-heading text-white">Gallery</h2>
        <hr class="light my-4">
             <h5 class="section-heading  text-white" style="text-align: left; line-height: 1.8">
            <p style="font-size: 1.5em; text-align: center; margin-top: 20px;">
          TBD
        </p>
         
      <!-- 标题
        <div class="text-faded" style="text-align: left; color: white; font-size: 24px; line-height: 1.8; font-weight: normal;">
          <strong>ICME AIART GALLERY</strong>
        </div>

        <!-- 描述 
        <div class="text-faded" style="text-align: left; color: white; font-size: 18px; line-height: 1.8; font-weight: normal;">
          As a highlight of IEEE AIART 2025, ICME AIART Gallery brings together AI-powered artworks from around the world. It’s a global platform for creativity and communication, exploring how AI is shaping the landscape and future of art.
        </div>
        <br>
        <!-- 图片居中 
        <div class="text-center">
          <img src="images/gallery.png" alt="AIART Gallery Image" style="max-width: 80%; height: auto;" />
        </div>
        <br>
        <!-- 副标题 
     <div class="text-faded" style="text-align: center; color: white; font-size: 18px; line-height: 1.8; font-weight: normal;">
  <strong>Intelligence Reimagined: The Convergence of Art and AI</strong>
</div>

        <!-- 外部链接
     <div class="text-faded" style="text-align: center; color: white; font-size: 16px; line-height: 1.8; font-weight: normal;">
          <a href="https://sites.google.com/view/2025aiart-gallery" target="_blank">
            https://sites.google.com/view/2025aiart-gallery
          </a>
        </div>

        <!-- 时间地点 
 <div class="text-faded" style="text-align: center; color: white; font-size: 18px; line-height: 1.8; font-weight: normal;">
  July 1–July 4, 2025
</div>
 <div class="text-faded" style="text-align: center; color: white; font-size: 18px; line-height: 1.8; font-weight: normal;">
  at La Cité Nantes Congress Centre, France
</div>

        <!-- 投稿说明
 <div class="text-faded" style="text-align: center; color: white; font-size: 18px; line-height: 1.8; font-weight: normal;">
  <strong>Call for AI artworks</strong>
</div>

        <!-- 投稿链接
     <div class="text-faded" style="text-align: center; color: white; font-size: 16px; font-style: italic; line-height: 1.8; font-weight: normal;">
          (Submission Link: 
          <a href="https://forms.office.com/r/HjQ8MYY18q?origin=lprLink" target="_blank">
            https://forms.office.com/r/HjQ8MYY18q?origin=lprLink
          </a>)
   </div>
        <!-- 补充说明 
        <div class="text-faded" style="text-align: left; color: white; font-size: 18px; line-height: 1.8; font-weight: normal;">
          <strong>Both AI-generated or AI-assisted artworks and traditional art exploring AI-related themes are welcome.</strong>
        </div>
        <div class="text-faded" style="text-align: left; color: white; font-size: 18px; line-height: 1.8; font-weight: normal;">
          <strong>Submission Deadline:</strong> Now until April 30, 2025.
        </div>
        <br><br>
       <div class="text-faded" style="text-align: left; color: white; font-size: 24px; line-height: 1.8; font-weight: normal;">
          <strong>Douyin Digital Art Calling Order - AIART Special Exhibition</strong>
        </div>     
     <div class="text-faded" style="text-align: left; color: white; font-size: 18px; line-height: 1.8; font-weight: normal;">
        In order to promote the development of AI art and to present the diversity of AI art in China and around the world, Douyin ART and IEEE AIART Workshop have launched the “Douyin Digital Art Calling Order - AIART Special Exhibition in Nantes, France”.
        </div>
  <div class="text-faded" style="text-align: left; color: white; font-size: 18px; line-height: 1.8; font-weight: normal;">
      From today to June 26, 2025, post your AI artwork on the Douyin platform with the tag #Douyin Digital Art Call #AIART Exhibition in Nantes, France, and you can apply for the program. The IEEE AIART Technical Program Committee will select the best works online. Selected artists will have the opportunity to send their works to the AIART Special Exhibition in Nantes, France.
        </div>
        <br>
        <!-- 图片居中 
        <div class="text-center">
          <img src="images/douyin.jpg" alt="AIART Gallery Image" style="max-width: 80%; height: auto;" />
        </div>
<br>
      <!-- 副标题 
     <div class="text-faded" style="text-align: left; color: white; font-size: 18px; line-height: 1.8; font-weight: normal;">
  <strong>Event Video Link:</strong>
</div>
        <!-- 外部链接 
     <div class="text-faded" style="text-align: left; color: white; font-size: 18px; line-height: 1.8; font-weight: normal;">
          <a href="https://www.douyin.com/note/7517866188744658226" target="_blank">
            https://www.douyin.com/note/7517866188744658226
          </a>
        </div>
        <br><br>-->
      </div>
    </div>
  </div>
</section>


 
<section id="Book">
  <div class="container">
    <div class="row">
      <div class="col-lg-10 mx-auto text-center">

        <h2 class="section-heading">Book</h2>
        <hr class="dark my-4">

        <div class="text-center mt-4">

          <!-- Title -->
          <div class="mb-3"
               style="text-align:left; color: black; font-size:24px; line-height:1.8;">
            <strong>Artificial Intelligence for Art Creation and Understanding</strong>
          </div>

          <!-- Editor -->
          <div class="mb-4 text-muted"
               style="text-align:left; font-size:20px; line-height:1.8; font-style:italic; font-weight:normal;">
            Edited By
            <a href="https://www.taylorfrancis.com/search?contributorName=Luntian%20Mou&contributorRole=editor&redirectFromPDP=true&context=ubx"
               target="_blank">
              Luntian Mou
            </a>
          </div>

      
          <p class="text-muted mb-4"
             style="text-align:justify; font-size:18px; line-height:1.8; font-weight:normal;color: black;">
            <strong>eBook Published:</strong> 29 August 2024<br>
            <strong>Imprint:</strong> CRC Press<br>
            <strong>DOI:</strong>
            <a href="https://doi.org/10.1201/9781003406273" target="_blank">
              https://doi.org/10.1201/9781003406273
            </a>
          </p>

          <img class="mb-3" src="images/book.jpg"
               style="height:auto; width:100%; max-width:400px; border-radius:20px;" />

          <br>

          <p class="mb-3" style="text-align:left; color: black; font-size:24px;">
            <strong>ABSTRACT</strong>
          </p>

          <p class="text-muted mb-0"
             style="text-align:justify; font-size:18px; line-height:1.8; font-weight:normal;">
            AI-Generated Content (AIGC) is a revolutionary engine for digital content generation. In the area of art, AI has achieved remarkable advancements. AI is capable of not only creating paintings or music comparable to human masterpieces, but it also understands and appreciates artwork. For professionals and amateurs, AI is an enabling tool and an opportunity to enjoy a new world of art.
          </p>

          <p class="text-muted mb-0"
             style="text-align:justify; font-size:18px; line-height:1.8; font-weight:normal;">
            This book aims to present the state-of-the-art AI technologies for art creation, understanding, and evaluation. The contents include a survey on cross-modal generation of visual and auditory content, explainable AI and music, AI-enabled robotic theater for Chinese folk art, AI for ancient Chinese music restoration and reproduction, AI for brainwave opera, artistic text style transfer, data-driven automatic choreography, Human-AI collaborative sketching, personalized music recommendation and generation based on emotion and memory (MemoMusic), understanding music and emotion from the brain, music question answering, emotional quality evaluation for generated music, and AI for image aesthetic evaluation.
          </p>

          <p class="text-muted mb-0"
             style="text-align:justify; font-size:18px; line-height:1.8; font-weight:normal;">
            The key features of the book are as follows:
          </p>

          <ul style="text-align:left; font-size:18px; line-height:1.8; color: black;">
            <li class="text-muted"><strong>AI for Art is a fascinating cross-disciplinary field for the academic community as well as the public.</strong></li>
            <li class="text-muted"><strong>Each chapter is an independent interesting topic, which provides an entry for corresponding readers.</strong></li>
            <li class="text-muted"><strong>It presents SOTA AI technologies for art creation and understanding.</strong></li>
            <li class="text-muted"><strong>The artistry and appreciation of the book is wide-ranging – for example, the combination of AI with traditional Chinese art.</strong></li>
          </ul>

          <br>

          <p class="text-muted mb-4"
             style="text-align:justify; font-size:18px; line-height:1.8; font-weight:normal;">
            This book is dedicated to the international cross-disciplinary AI Art community: professors, students, researchers, and engineers from AI (machine learning, computer vision, multimedia computing, affective computing, robotics, etc.), art (painting, music, dance, fashion, design, etc.), cognitive science, and psychology. General audiences can also benefit from this book.
          </p>

          <p class="mb-3" style="text-align:left; color: black; font-size:24px;">
            <strong>Purchase Links:</strong>
          </p>

          <ul style="text-align:left; font-size:18px; line-height:1.8;">
            <li class="text-muted">
              <a href="https://www.amazon.com/Artificial-Intelligence-Understanding-Multimedia-Communication/dp/1032523603" target="_blank">
                https://www.amazon.com/Artificial-Intelligence-Understanding-Multimedia-Communication/dp/1032523603
              </a>
            </li>
            <li class="text-muted">
              <a href="https://www.routledge.com/Artificial-Intelligence-for-Art-Creation-and-Understanding/Mou/p/book/9781032523606" target="_blank">
                https://www.routledge.com/Artificial-Intelligence-for-Art-Creation-and-Understanding/Mou/p/book/9781032523606
              </a>
            </li>
            <li class="text-muted">
              <a href="https://item.jd.com/10112811679589.html" target="_blank">
                https://item.jd.com/10112811679589.html
              </a>
            </li>
            <li class="text-muted">
              <a href="https://product.dangdang.com/11804604409.html" target="_blank">
                https://product.dangdang.com/11804604409.html
              </a>
            </li>
          </ul>

        </div>
      </div>
    </div>
  </div>
</section>





<section class="bg-primary" id="history">
  <div class="container">
    <div class="row">
      <div class="col-lg-10 mx-auto text-center">

        <h2 class="section-heading text-white">History</h2>
        <hr class="light my-4">

        <div class="text-white"
             style="text-align:left; font-size:18px color: white; line-height:1.8;">

          <ul style="padding-left:1.2rem; margin-bottom:1rem;">
            <li>
              AIART 2025:
              <a href="https://aiart-2025.github.io/" target="_blank">
                https://aiart-2025.github.io/
              </a>, Nantes, France, with ICME 2025
            </li>
            <li>
              AIART 2024:
              <a href="https://aiart2024.github.io/" target="_blank">
                https://aiart2024.github.io/
              </a>, Niagra Falls, Canada, with ICME 2024
            </li>
            <li>
              AIART 2023:
              <a href="https://aiart2023.github.io/" target="_blank">
                https://aiart2023.github.io/
              </a>, Brisbane, Australia, with ICME 2023
            </li>
            <li>
              AIART 2022:
              <a href="https://aiart2022.github.io/" target="_blank">
                https://aiart2022.github.io/
              </a>, online, with ICME 2022
            </li>
            <li>
              AIART 2021:
              <a href="https://aiart2021.github.io/" target="_blank">
                https://aiart2021.github.io/
              </a>, online, with MIPR 2021
            </li>
            <li>
              AIART 2020:
              <a href="https://aiart2020.github.io/" target="_blank">
                https://aiart2020.github.io/
              </a>, online, with MIPR 2020
            </li>
            <li>
              AIART 2019:
              <a href="https://aiart2019.github.io/" target="_blank">
                https://aiart2019.github.io/
              </a>, San Jose, USA, with MIPR 2019
            </li>
          </ul>
        </div>

      </div>
    </div>
  </div>
</section>





  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="vendor/jquery-easing/jquery.easing.min.js"></script>
  <script src="vendor/scrollreveal/scrollreveal.min.js"></script>
  <script src="vendor/magnific-popup/jquery.magnific-popup.min.js"></script>

  <!-- Custom scripts for this template -->
  <script src="js/creative.min.js"></script>

</body>

</html>
